{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0805 16:30:33.035462000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035482000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035488000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035493000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035498000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035502000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035506000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035510000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035515000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035531000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035537000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035541000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035546000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035550000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035554000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.035558000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.036052000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n",
      "E0805 16:30:33.070014000 140704415147776 client_channel.cc:667]        chand=0x7ff4280f9aa0: Illegal keepalive throttling value \n"
     ]
    }
   ],
   "source": [
    "from pyannote.database import registry\n",
    "from pyannote.audio.tasks import SpeakerDiarization, Segmentation\n",
    "from google.cloud import secretmanager\n",
    "from pyannote.audio import Model\n",
    "from pyannote.audio import Pipeline\n",
    "from pyannote.audio import tasks\n",
    "import os\n",
    "from pyannote.database import get_protocol, FileFinder\n",
    "\n",
    "def access_secret_version(project_id, secret_id, version_id):\n",
    "    \"\"\"\n",
    "    Access the payload for the given secret version if one exists. The version\n",
    "    can be a version number as a string (e.g. \"5\") or an alias (e.g. \"latest\").\n",
    "    \"\"\"\n",
    "\n",
    "    client = secretmanager.SecretManagerServiceClient()\n",
    "\n",
    "    # Build the resource name of the secret version.\n",
    "    name = f\"projects/{project_id}/secrets/{secret_id}/versions/{version_id}\"\n",
    "\n",
    "    # Access the secret version.\n",
    "    response = client.access_secret_version(name=name)\n",
    "\n",
    "    # Return the decoded payload.\n",
    "    return response.payload.data.decode('UTF-8')\n",
    "\n",
    "HF_KEY = access_secret_version(1076126751560, \"huggingface-api-key\", \"latest\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.1. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"PYANNOTE_DATABASE_CONFIG\"] = \"/Users/StephenWitkowski/Projects/broadcastify-transcription/data/broadcastify_database.yaml\"\n",
    "registry.load_database(\"/Users/StephenWitkowski/Projects/broadcastify-transcription/data/broadcastify_database.yaml\")\n",
    "\n",
    "dataset = get_protocol(\"MyDatabase.SpeakerDiarization.MyProtocol\", {\"audio\": FileFinder()})\n",
    "\n",
    "pretrained_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this takes approximately 2min to run on Google Colab GPU\n",
    "from pyannote.metrics.diarization import DiarizationErrorRate\n",
    "metric = DiarizationErrorRate()\n",
    "\n",
    "for file in dataset.test():\n",
    "    # apply pretrained pipeline\n",
    "    file[\"pretrained pipeline\"] = pretrained_pipeline(file)\n",
    "\n",
    "    # evaluate its performance\n",
    "    metric(file[\"annotation\"], file[\"pretrained pipeline\"], uem=file[\"annotated\"])\n",
    "\n",
    "    break\n",
    "\n",
    "print(f\"The pretrained pipeline reaches a Diarization Error Rate (DER) of {100 * abs(metric):.1f}% on {dataset.name} test set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `Segmentation` not found.\n"
     ]
    }
   ],
   "source": [
    "Segmentation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = Segmentation(\n",
    "    dataset, \n",
    "    duration=2,\n",
    "    max_speakers_per_chunk = 2,\n",
    "    max_speakers_per_frame = 1,\n",
    "    batch_size=32,\n",
    "    num_workers=2, \n",
    "    loss=\"bce\")\n",
    "model.task = task\n",
    "model.setup(stage=\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name              </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">      In sizes </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">                                   Out sizes </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ sincnet           │ SincNet          │ 42.6 K │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [1, 1, 32000] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                [1, 60, 115] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ lstm              │ LSTM             │  1.4 M │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">  [1, 115, 60] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [[1, 115, 256], [[8, 1, 128], [8, 1, 128]]] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ linear            │ ModuleList       │ 49.4 K │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                           ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ classifier        │ Linear           │    387 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\"> [1, 115, 128] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                 [1, 115, 3] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 4 </span>│ activation        │ LogSoftmax       │      0 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">   [1, 115, 3] </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                 [1, 115, 3] </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 5 </span>│ powerset          │ Powerset         │      0 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                           ? </span>│\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 6 </span>│ validation_metric │ MetricCollection │      0 │<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">             ? </span>│<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">                                           ? </span>│\n",
       "└───┴───────────────────┴──────────────────┴────────┴───────────────┴─────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName             \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m     In sizes\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35m                                  Out sizes\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ sincnet           │ SincNet          │ 42.6 K │\u001b[37m \u001b[0m\u001b[37m[1, 1, 32000]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                               [1, 60, 115]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ lstm              │ LSTM             │  1.4 M │\u001b[37m \u001b[0m\u001b[37m [1, 115, 60]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m[[1, 115, 256], [[8, 1, 128], [8, 1, 128]]]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ linear            │ ModuleList       │ 49.4 K │\u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                          ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ classifier        │ Linear           │    387 │\u001b[37m \u001b[0m\u001b[37m[1, 115, 128]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                [1, 115, 3]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m4\u001b[0m\u001b[2m \u001b[0m│ activation        │ LogSoftmax       │      0 │\u001b[37m \u001b[0m\u001b[37m  [1, 115, 3]\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                [1, 115, 3]\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m5\u001b[0m\u001b[2m \u001b[0m│ powerset          │ Powerset         │      0 │\u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                          ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "│\u001b[2m \u001b[0m\u001b[2m6\u001b[0m\u001b[2m \u001b[0m│ validation_metric │ MetricCollection │      0 │\u001b[37m \u001b[0m\u001b[37m            ?\u001b[0m\u001b[37m \u001b[0m│\u001b[37m \u001b[0m\u001b[37m                                          ?\u001b[0m\u001b[37m \u001b[0m│\n",
       "└───┴───────────────────┴──────────────────┴────────┴───────────────┴─────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 1.5 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 1.5 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 5                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 1.5 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 1.5 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 5                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ced0578b5add4db6b8960eadc8d50bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# this takes approximately 15min to run on Google Colab GPU\n",
    "from types import MethodType\n",
    "from torch.optim import Adam\n",
    "from pytorch_lightning.callbacks import (\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    RichProgressBar,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# we use Adam optimizer with 1e-4 learning rate\n",
    "def configure_optimizers(self):\n",
    "    return Adam(self.parameters(), lr=1e-4)\n",
    "\n",
    "model.configure_optimizers = MethodType(configure_optimizers, model)\n",
    "\n",
    "# we monitor diarization error rate on the validation set\n",
    "# and use to keep the best checkpoint and stop early\n",
    "monitor, direction = task.val_monitor\n",
    "checkpoint = ModelCheckpoint(\n",
    "    monitor=monitor,\n",
    "    mode=direction,\n",
    "    save_top_k=1,\n",
    "    every_n_epochs=1,\n",
    "    save_last=False,\n",
    "    save_weights_only=False,\n",
    "    filename=\"{epoch}\",\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor=monitor,\n",
    "    mode=direction,\n",
    "    min_delta=0.0,\n",
    "    patience=10,\n",
    "    strict=True,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "callbacks = [RichProgressBar(), checkpoint, early_stopping]\n",
    "\n",
    "# we train for at most 20 epochs (might be shorter in case of early stopping)\n",
    "from pytorch_lightning import Trainer\n",
    "trainer = Trainer(accelerator=\"cpu\", \n",
    "                    logger=False,\n",
    "                  callbacks=callbacks, \n",
    "                  max_epochs=1,\n",
    "                  gradient_clip_val=0.5)\n",
    "trainer.fit(model)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = checkpoint.best_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHECKPOINT_JOIN_CHAR',\n",
       " 'CHECKPOINT_NAME_LAST',\n",
       " 'FILE_EXTENSION',\n",
       " 'STARTING_VERSION',\n",
       " '_ModelCheckpoint__init_ckpt_dir',\n",
       " '_ModelCheckpoint__init_monitor_mode',\n",
       " '_ModelCheckpoint__init_triggers',\n",
       " '_ModelCheckpoint__resolve_ckpt_dir',\n",
       " '_ModelCheckpoint__validate_init_configuration',\n",
       " '_ModelCheckpoint__warn_if_dir_not_empty',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_every_n_epochs',\n",
       " '_every_n_train_steps',\n",
       " '_find_last_checkpoints',\n",
       " '_format_checkpoint_name',\n",
       " '_fs',\n",
       " '_generate_state_key',\n",
       " '_get_metric_interpolated_filepath_name',\n",
       " '_last_global_step_saved',\n",
       " '_last_time_checked',\n",
       " '_legacy_state_key',\n",
       " '_monitor_candidates',\n",
       " '_remove_checkpoint',\n",
       " '_save_checkpoint',\n",
       " '_save_last_checkpoint',\n",
       " '_save_monitor_checkpoint',\n",
       " '_save_none_monitor_checkpoint',\n",
       " '_save_on_train_epoch_end',\n",
       " '_save_topk_checkpoint',\n",
       " '_should_save_on_train_epoch_end',\n",
       " '_should_skip_saving_checkpoint',\n",
       " '_train_time_interval',\n",
       " '_update_best_and_save',\n",
       " 'auto_insert_metric_name',\n",
       " 'best_k_models',\n",
       " 'best_model_path',\n",
       " 'best_model_score',\n",
       " 'check_monitor_top_k',\n",
       " 'current_score',\n",
       " 'dirpath',\n",
       " 'every_n_epochs',\n",
       " 'file_exists',\n",
       " 'filename',\n",
       " 'format_checkpoint_name',\n",
       " 'kth_best_model_path',\n",
       " 'kth_value',\n",
       " 'last_model_path',\n",
       " 'load_state_dict',\n",
       " 'log',\n",
       " 'log_dict',\n",
       " 'mode',\n",
       " 'monitor',\n",
       " 'on_after_backward',\n",
       " 'on_before_backward',\n",
       " 'on_before_optimizer_step',\n",
       " 'on_before_zero_grad',\n",
       " 'on_exception',\n",
       " 'on_fit_end',\n",
       " 'on_fit_start',\n",
       " 'on_load_checkpoint',\n",
       " 'on_predict_batch_end',\n",
       " 'on_predict_batch_start',\n",
       " 'on_predict_end',\n",
       " 'on_predict_epoch_end',\n",
       " 'on_predict_epoch_start',\n",
       " 'on_predict_start',\n",
       " 'on_sanity_check_end',\n",
       " 'on_sanity_check_start',\n",
       " 'on_save_checkpoint',\n",
       " 'on_test_batch_end',\n",
       " 'on_test_batch_start',\n",
       " 'on_test_end',\n",
       " 'on_test_epoch_end',\n",
       " 'on_test_epoch_start',\n",
       " 'on_test_start',\n",
       " 'on_train_batch_end',\n",
       " 'on_train_batch_start',\n",
       " 'on_train_end',\n",
       " 'on_train_epoch_end',\n",
       " 'on_train_epoch_start',\n",
       " 'on_train_start',\n",
       " 'on_validation_batch_end',\n",
       " 'on_validation_batch_start',\n",
       " 'on_validation_end',\n",
       " 'on_validation_epoch_end',\n",
       " 'on_validation_epoch_start',\n",
       " 'on_validation_start',\n",
       " 'save_last',\n",
       " 'save_top_k',\n",
       " 'save_weights_only',\n",
       " 'setup',\n",
       " 'state_dict',\n",
       " 'state_key',\n",
       " 'teardown',\n",
       " 'to_yaml',\n",
       " 'verbose']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__class__',\n",
       " '__contains__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getnewargs__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__mod__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmod__',\n",
       " '__rmul__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'capitalize',\n",
       " 'casefold',\n",
       " 'center',\n",
       " 'count',\n",
       " 'encode',\n",
       " 'endswith',\n",
       " 'expandtabs',\n",
       " 'find',\n",
       " 'format',\n",
       " 'format_map',\n",
       " 'index',\n",
       " 'isalnum',\n",
       " 'isalpha',\n",
       " 'isascii',\n",
       " 'isdecimal',\n",
       " 'isdigit',\n",
       " 'isidentifier',\n",
       " 'islower',\n",
       " 'isnumeric',\n",
       " 'isprintable',\n",
       " 'isspace',\n",
       " 'istitle',\n",
       " 'isupper',\n",
       " 'join',\n",
       " 'ljust',\n",
       " 'lower',\n",
       " 'lstrip',\n",
       " 'maketrans',\n",
       " 'partition',\n",
       " 'removeprefix',\n",
       " 'removesuffix',\n",
       " 'replace',\n",
       " 'rfind',\n",
       " 'rindex',\n",
       " 'rjust',\n",
       " 'rpartition',\n",
       " 'rsplit',\n",
       " 'rstrip',\n",
       " 'split',\n",
       " 'splitlines',\n",
       " 'startswith',\n",
       " 'strip',\n",
       " 'swapcase',\n",
       " 'title',\n",
       " 'translate',\n",
       " 'upper',\n",
       " 'zfill']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(finetuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.0.5. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint --file ../../../.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model was trained with pyannote.audio 0.0.1, yours is 2.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.0.1. Bad things might happen unless you revert torch to 1.x.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'segmentation': {'min_duration_off': 0.5817029604921046,\n",
       "  'threshold': 0.4442333667381752},\n",
       " 'clustering': {'method': 'centroid',\n",
       "  'min_cluster_size': 15,\n",
       "  'threshold': 0.7153814381597874}}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pretrained_pipeline = Pipeline.from_pretrained(\"pyannote/speaker-diarization\", use_auth_token=True)\n",
    "\n",
    "pretrained_hyperparameters = pretrained_pipeline.parameters(instantiated=True)\n",
    "pretrained_hyperparameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "parameter 'threshold' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[53], line 10\u001b[0m\n\u001b[1;32m      5\u001b[0m pipeline \u001b[39m=\u001b[39m SpeakerDiarization(\n\u001b[1;32m      6\u001b[0m     segmentation\u001b[39m=\u001b[39mfinetuned_model,\n\u001b[1;32m      7\u001b[0m     clustering\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mOracleClustering\u001b[39m\u001b[39m\"\u001b[39m,  \n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m      9\u001b[0m \u001b[39m# as reported in the technical report, min_duration_off can safely be set to 0.0\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m pipeline\u001b[39m.\u001b[39;49mfreeze(pretrained_hyperparameters)\n\u001b[1;32m     11\u001b[0m pipeline\u001b[39m.\u001b[39mfreeze({\u001b[39m\"\u001b[39m\u001b[39msegmentation\u001b[39m\u001b[39m\"\u001b[39m: {\u001b[39m\"\u001b[39m\u001b[39mmin_duration_off\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m0.0\u001b[39m}})\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/pyannote/pipeline/pipeline.py:386\u001b[0m, in \u001b[0;36mPipeline.freeze\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    381\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    382\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39monly parameters of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m pipeline can \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbe frozen (not the whole pipeline)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         )\n\u001b[1;32m    385\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipelines[name]\u001b[39m.\u001b[39;49mfreeze(value)\n\u001b[1;32m    387\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39m# instantiate parameter value\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/pyannote/pipeline/pipeline.py:395\u001b[0m, in \u001b[0;36mPipeline.freeze\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    394\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 395\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    397\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: parameter 'threshold' does not exist"
     ]
    }
   ],
   "source": [
    "# this takes approximately 5min to run on Google Colab GPU\n",
    "from pyannote.audio.pipelines import SpeakerDiarization\n",
    "from pyannote.pipeline import Optimizer\n",
    "\n",
    "pipeline = SpeakerDiarization(\n",
    "    segmentation=finetuned_model,\n",
    "    clustering=\"OracleClustering\",  \n",
    ")\n",
    "# as reported in the technical report, min_duration_off can safely be set to 0.0\n",
    "pipeline.freeze(pretrained_hyperparameters)\n",
    "pipeline.freeze({\"segmentation\": {\"min_duration_off\": 0.0}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'segmentation': {'min_duration_off': <pyannote.pipeline.parameter.Frozen at 0x160a98450>},\n",
       " 'clustering': {}}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0;31mInit signature:\u001b[0m\n",
      "\u001b[0mOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpipeline\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpyannote\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPipeline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mdb\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mstudy_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0msampler\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBaseSampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m    \u001b[0mpruner\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpruners\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBasePruner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
      "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mDocstring:\u001b[0m     \n",
      "Pipeline optimizer\n",
      "\n",
      "Parameters\n",
      "----------\n",
      "pipeline : `Pipeline`\n",
      "    Pipeline.\n",
      "db : `Path`, optional\n",
      "    Path to iteration database on disk.\n",
      "study_name : `str`, optional\n",
      "    Name of study. In case it already exists, study will continue from\n",
      "    there. # TODO -- generate this automatically\n",
      "sampler : `str` or sampler instance, optional\n",
      "    Algorithm for value suggestion. Must be one of \"RandomSampler\" or\n",
      "    \"TPESampler\", or a sampler instance. Defaults to \"TPESampler\".\n",
      "pruner : `str` or pruner instance, optional\n",
      "    Algorithm for early pruning of trials. Must be one of \"MedianPruner\" or\n",
      "    \"SuccessiveHalvingPruner\", or a pruner instance.\n",
      "    Defaults to no pruning.\n",
      "\u001b[0;31mFile:\u001b[0m           ~/micromamba/envs/broadcastify/lib/python3.11/site-packages/pyannote/pipeline/optimizer.py\n",
      "\u001b[0;31mType:\u001b[0m           type\n",
      "\u001b[0;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "Optimizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n",
      "Best segmentation threshold so far: {'loss': 0.40268080172031917, 'params': {'segmentation': {'min_duration_off': 0.5817029604921046}, 'clustering': {}}}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optimizer = Optimizer(pipeline)\n",
    "dev_set = list(dataset.development())\n",
    "\n",
    "iterations = optimizer.tune_iter(dev_set, show_progress=False)\n",
    "best_loss = 1.0\n",
    "for i, iteration in enumerate(iterations):\n",
    "    print(f\"Best segmentation threshold so far: {iteration}\")\n",
    "    if i > 20: break   # 50 iterations should give slightly better results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': 0.4876474198398448,\n",
       " 'params': {'segmentation': {'min_duration_off': 0.0}, 'clustering': {}}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = pretrained_pipeline.parameters(instantiated=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "parameter 'threshold' does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# this takes approximately 5min to run on Google Colab GPU\u001b[39;00m\n\u001b[1;32m      2\u001b[0m pipeline \u001b[39m=\u001b[39m SpeakerDiarization(\n\u001b[1;32m      3\u001b[0m     segmentation\u001b[39m=\u001b[39mfinetuned_model,\n\u001b[1;32m      4\u001b[0m     embedding\u001b[39m=\u001b[39mpretrained_pipeline\u001b[39m.\u001b[39membedding,\n\u001b[1;32m      5\u001b[0m     embedding_exclude_overlap\u001b[39m=\u001b[39mpretrained_pipeline\u001b[39m.\u001b[39membedding_exclude_overlap,\n\u001b[1;32m      6\u001b[0m     clustering\u001b[39m=\u001b[39mpretrained_pipeline\u001b[39m.\u001b[39mklustering,\n\u001b[1;32m      7\u001b[0m )\n\u001b[0;32m----> 9\u001b[0m pipeline\u001b[39m.\u001b[39;49mfreeze(params)\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/pyannote/pipeline/pipeline.py:386\u001b[0m, in \u001b[0;36mPipeline.freeze\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    381\u001b[0m         msg \u001b[39m=\u001b[39m (\n\u001b[1;32m    382\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39monly parameters of \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m pipeline can \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    383\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbe frozen (not the whole pipeline)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m         )\n\u001b[1;32m    385\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[0;32m--> 386\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_pipelines[name]\u001b[39m.\u001b[39;49mfreeze(value)\n\u001b[1;32m    387\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    389\u001b[0m \u001b[39m# instantiate parameter value\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/pyannote/pipeline/pipeline.py:395\u001b[0m, in \u001b[0;36mPipeline.freeze\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m    392\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    394\u001b[0m     msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m does not exist\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 395\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n\u001b[1;32m    397\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: parameter 'threshold' does not exist"
     ]
    }
   ],
   "source": [
    "# this takes approximately 5min to run on Google Colab GPU\n",
    "pipeline = SpeakerDiarization(\n",
    "    segmentation=finetuned_model,\n",
    "    embedding=pretrained_pipeline.embedding,\n",
    "    embedding_exclude_overlap=pretrained_pipeline.embedding_exclude_overlap,\n",
    "    clustering=pretrained_pipeline.klustering,\n",
    ")\n",
    "\n",
    "pipeline.freeze(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "A pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/pyannote/audio/core/pipeline.py:302\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 302\u001b[0m     default_parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdefault_parameters()\n\u001b[1;32m    303\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/pyannote/audio/pipelines/speaker_diarization.py:188\u001b[0m, in \u001b[0;36mSpeakerDiarization.default_parameters\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdefault_parameters\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> 188\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m()\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# 4. apply pretrained pipeline\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m diarization \u001b[39m=\u001b[39m pipeline(\u001b[39m\"\u001b[39;49m\u001b[39m/Users/StephenWitkowski/Projects/broadcastify-transcription/data/audio/input_chunk_102.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# 5. print the result\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m turn, _, speaker \u001b[39min\u001b[39;00m diarization\u001b[39m.\u001b[39mitertracks(yield_label\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/pyannote/audio/core/pipeline.py:304\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, file, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m     default_parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdefault_parameters()\n\u001b[1;32m    303\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mA pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m     )\n\u001b[1;32m    308\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    309\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minstantiate(default_parameters)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: A pipeline must be instantiated with `pipeline.instantiate(parameters)` before it can be applied."
     ]
    }
   ],
   "source": [
    "\n",
    "# 4. apply pretrained pipeline\n",
    "diarization = pipeline(\"/Users/StephenWitkowski/Projects/broadcastify-transcription/data/audio/input_chunk_102.wav\")\n",
    "\n",
    "# 5. print the result\n",
    "for turn, _, speaker in diarization.itertracks(yield_label=True):\n",
    "    print(f\"start={turn.start:.1f}s stop={turn.end:.1f}s speaker_{speaker}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.from_pretrained(finetuned_model, use_auth_token=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model(\u001b[39m\"\u001b[39;49m\u001b[39m/Users/StephenWitkowski/Projects/broadcastify-transcription/data/audio/input_chunk_13.wav\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/pyannote/audio/models/segmentation/PyanNet.py:172\u001b[0m, in \u001b[0;36mPyanNet.forward\u001b[0;34m(self, waveforms)\u001b[0m\n\u001b[1;32m    160\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, waveforms: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m    161\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Pass forward\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \n\u001b[1;32m    163\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[39m    scores : (batch, frame, classes)\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 172\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msincnet(waveforms)\n\u001b[1;32m    174\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhparams\u001b[39m.\u001b[39mlstm[\u001b[39m\"\u001b[39m\u001b[39mmonolithic\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    175\u001b[0m         outputs, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlstm(\n\u001b[1;32m    176\u001b[0m             rearrange(outputs, \u001b[39m\"\u001b[39m\u001b[39mbatch feature frame -> batch frame feature\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    177\u001b[0m         )\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/pyannote/audio/models/blocks/sincnet.py:81\u001b[0m, in \u001b[0;36mSincNet.forward\u001b[0;34m(self, waveforms)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, waveforms: torch\u001b[39m.\u001b[39mTensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m torch\u001b[39m.\u001b[39mTensor:\n\u001b[1;32m     74\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Pass forward\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \n\u001b[1;32m     76\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[39m    ----------\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[39m    waveforms : (batch, channel, sample)\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 81\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwav_norm1d(waveforms)\n\u001b[1;32m     83\u001b[0m     \u001b[39mfor\u001b[39;00m c, (conv1d, pool1d, norm1d) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\n\u001b[1;32m     84\u001b[0m         \u001b[39mzip\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconv1d, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpool1d, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnorm1d)\n\u001b[1;32m     85\u001b[0m     ):\n\u001b[1;32m     87\u001b[0m         outputs \u001b[39m=\u001b[39m conv1d(outputs)\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/torch/nn/modules/instancenorm.py:69\u001b[0m, in \u001b[0;36m_InstanceNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m---> 69\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_input_dim(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m     71\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_no_batch_dim():\n\u001b[1;32m     72\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle_no_batch_input(\u001b[39minput\u001b[39m)\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/torch/nn/modules/instancenorm.py:148\u001b[0m, in \u001b[0;36mInstanceNorm1d._check_input_dim\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_input_dim\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[0;32m--> 148\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mdim() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m):\n\u001b[1;32m    149\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mexpected 2D or 3D input (got \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39mD input)\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    150\u001b[0m                          \u001b[39m.\u001b[39mformat(\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mdim()))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'dim'"
     ]
    }
   ],
   "source": [
    "model(\"/Users/StephenWitkowski/Projects/broadcastify-transcription/data/audio/input_chunk_13.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CHECKPOINT_HYPER_PARAMS_KEY',\n",
       " 'CHECKPOINT_HYPER_PARAMS_NAME',\n",
       " 'CHECKPOINT_HYPER_PARAMS_TYPE',\n",
       " 'LINEAR_DEFAULTS',\n",
       " 'LSTM_DEFAULTS',\n",
       " 'SINCNET_DEFAULTS',\n",
       " 'T_destination',\n",
       " '_DeviceDtypeModuleMixin__update_properties',\n",
       " '_LightningModule__check_allowed',\n",
       " '_LightningModule__check_not_nested',\n",
       " '_LightningModule__to_tensor',\n",
       " '_Model__by_name',\n",
       " '_Model__example_input_array',\n",
       " '_Model__up_to',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__jit_unused_properties__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_apply',\n",
       " '_apply_batch_transfer_handler',\n",
       " '_automatic_optimization',\n",
       " '_backward_hooks',\n",
       " '_backward_pre_hooks',\n",
       " '_buffers',\n",
       " '_call_batch_hook',\n",
       " '_call_impl',\n",
       " '_compiler_ctx',\n",
       " '_current_fx_name',\n",
       " '_device',\n",
       " '_dtype',\n",
       " '_example_input_array',\n",
       " '_fabric',\n",
       " '_fabric_optimizers',\n",
       " '_forward_hooks',\n",
       " '_forward_hooks_with_kwargs',\n",
       " '_forward_pre_hooks',\n",
       " '_forward_pre_hooks_with_kwargs',\n",
       " '_get_backward_hooks',\n",
       " '_get_backward_pre_hooks',\n",
       " '_get_name',\n",
       " '_hparams',\n",
       " '_hparams_initial',\n",
       " '_hparams_name',\n",
       " '_is_full_backward_hook',\n",
       " '_jit_is_scripting',\n",
       " '_load_from_state_dict',\n",
       " '_load_state_dict_post_hooks',\n",
       " '_load_state_dict_pre_hooks',\n",
       " '_log_dict_through_fabric',\n",
       " '_log_hyperparams',\n",
       " '_maybe_warn_non_full_backward_hook',\n",
       " '_metric_attributes',\n",
       " '_modules',\n",
       " '_named_members',\n",
       " '_non_persistent_buffers_set',\n",
       " '_on_before_batch_transfer',\n",
       " '_param_requires_grad_state',\n",
       " '_parameters',\n",
       " '_register_load_state_dict_pre_hook',\n",
       " '_register_sharded_tensor_state_dict_hooks_if_available',\n",
       " '_register_state_dict_hook',\n",
       " '_replicate_for_data_parallel',\n",
       " '_save_to_state_dict',\n",
       " '_set_hparams',\n",
       " '_slow_forward',\n",
       " '_specifications',\n",
       " '_state_dict_hooks',\n",
       " '_state_dict_pre_hooks',\n",
       " '_task',\n",
       " '_to_hparams_dict',\n",
       " '_trainer',\n",
       " '_verify_is_manual_optimization',\n",
       " '_version',\n",
       " 'activation',\n",
       " 'add_module',\n",
       " 'all_gather',\n",
       " 'allow_zero_length_dataloader_with_multiple_devices',\n",
       " 'apply',\n",
       " 'audio',\n",
       " 'automatic_optimization',\n",
       " 'backward',\n",
       " 'bfloat16',\n",
       " 'buffers',\n",
       " 'build',\n",
       " 'call_super_init',\n",
       " 'children',\n",
       " 'classifier',\n",
       " 'clip_gradients',\n",
       " 'configure_callbacks',\n",
       " 'configure_gradient_clipping',\n",
       " 'configure_optimizers',\n",
       " 'configure_sharded_model',\n",
       " 'cpu',\n",
       " 'cuda',\n",
       " 'current_epoch',\n",
       " 'default_activation',\n",
       " 'device',\n",
       " 'double',\n",
       " 'dtype',\n",
       " 'dump_patches',\n",
       " 'eval',\n",
       " 'example_input_array',\n",
       " 'example_output',\n",
       " 'extra_repr',\n",
       " 'fabric',\n",
       " 'float',\n",
       " 'forward',\n",
       " 'freeze',\n",
       " 'freeze_by_name',\n",
       " 'freeze_up_to',\n",
       " 'from_pretrained',\n",
       " 'get_buffer',\n",
       " 'get_extra_state',\n",
       " 'get_parameter',\n",
       " 'get_submodule',\n",
       " 'global_rank',\n",
       " 'global_step',\n",
       " 'half',\n",
       " 'hparams',\n",
       " 'hparams_initial',\n",
       " 'ipu',\n",
       " 'linear',\n",
       " 'load_from_checkpoint',\n",
       " 'load_state_dict',\n",
       " 'local_rank',\n",
       " 'log',\n",
       " 'log_dict',\n",
       " 'logger',\n",
       " 'loggers',\n",
       " 'lr_scheduler_step',\n",
       " 'lr_schedulers',\n",
       " 'lstm',\n",
       " 'manual_backward',\n",
       " 'modules',\n",
       " 'named_buffers',\n",
       " 'named_children',\n",
       " 'named_modules',\n",
       " 'named_parameters',\n",
       " 'on_after_backward',\n",
       " 'on_after_batch_transfer',\n",
       " 'on_before_backward',\n",
       " 'on_before_batch_transfer',\n",
       " 'on_before_optimizer_step',\n",
       " 'on_before_zero_grad',\n",
       " 'on_fit_end',\n",
       " 'on_fit_start',\n",
       " 'on_gpu',\n",
       " 'on_load_checkpoint',\n",
       " 'on_predict_batch_end',\n",
       " 'on_predict_batch_start',\n",
       " 'on_predict_end',\n",
       " 'on_predict_epoch_end',\n",
       " 'on_predict_epoch_start',\n",
       " 'on_predict_model_eval',\n",
       " 'on_predict_start',\n",
       " 'on_save_checkpoint',\n",
       " 'on_test_batch_end',\n",
       " 'on_test_batch_start',\n",
       " 'on_test_end',\n",
       " 'on_test_epoch_end',\n",
       " 'on_test_epoch_start',\n",
       " 'on_test_model_eval',\n",
       " 'on_test_model_train',\n",
       " 'on_test_start',\n",
       " 'on_train_batch_end',\n",
       " 'on_train_batch_start',\n",
       " 'on_train_end',\n",
       " 'on_train_epoch_end',\n",
       " 'on_train_epoch_start',\n",
       " 'on_train_start',\n",
       " 'on_validation_batch_end',\n",
       " 'on_validation_batch_start',\n",
       " 'on_validation_end',\n",
       " 'on_validation_epoch_end',\n",
       " 'on_validation_epoch_start',\n",
       " 'on_validation_model_eval',\n",
       " 'on_validation_model_train',\n",
       " 'on_validation_start',\n",
       " 'optimizer_step',\n",
       " 'optimizer_zero_grad',\n",
       " 'optimizers',\n",
       " 'parameters',\n",
       " 'predict_dataloader',\n",
       " 'predict_step',\n",
       " 'prepare_data',\n",
       " 'prepare_data_per_node',\n",
       " 'print',\n",
       " 'register_backward_hook',\n",
       " 'register_buffer',\n",
       " 'register_forward_hook',\n",
       " 'register_forward_pre_hook',\n",
       " 'register_full_backward_hook',\n",
       " 'register_full_backward_pre_hook',\n",
       " 'register_load_state_dict_post_hook',\n",
       " 'register_module',\n",
       " 'register_parameter',\n",
       " 'register_state_dict_pre_hook',\n",
       " 'requires_grad_',\n",
       " 'save_hyperparameters',\n",
       " 'set_extra_state',\n",
       " 'setup',\n",
       " 'share_memory',\n",
       " 'sincnet',\n",
       " 'specifications',\n",
       " 'state_dict',\n",
       " 'task',\n",
       " 'task_dependent',\n",
       " 'teardown',\n",
       " 'test_dataloader',\n",
       " 'test_step',\n",
       " 'to',\n",
       " 'to_empty',\n",
       " 'to_onnx',\n",
       " 'to_torchscript',\n",
       " 'toggle_optimizer',\n",
       " 'train',\n",
       " 'train_dataloader',\n",
       " 'trainer',\n",
       " 'training',\n",
       " 'training_step',\n",
       " 'transfer_batch_to_device',\n",
       " 'type',\n",
       " 'unfreeze',\n",
       " 'unfreeze_by_name',\n",
       " 'unfreeze_up_to',\n",
       " 'untoggle_optimizer',\n",
       " 'val_dataloader',\n",
       " 'validation_step',\n",
       " 'xpu',\n",
       " 'zero_grad']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "HFValidationError",
     "evalue": "Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'PyanNet(\n  (sincnet): SincNet(\n    (wav_norm1d): InstanceNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n    (conv1d): ModuleList(\n      (0): Encoder(\n        (filterbank): ParamSincFB()\n      )\n      (1): Conv1d(80, 60, kernel_size=(5,), stride=(1,))\n      (2): Conv1d(60, 60, kernel_size=(5,), stride=(1,))\n    )\n    (pool1d): ModuleList(\n      (0-2): 3 x MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    )\n    (norm1d): ModuleList(\n      (0): InstanceNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n      (1-2): 2 x InstanceNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n    )\n  )\n  (lstm): LSTM(60, 128, num_layers=4, batch_first=True, dropout=0.5, bidirectional=True)\n  (linear): ModuleList(\n    (0): Linear(in_features=256, out_features=128, bias=True)\n    (1): Linear(in_features=128, out_features=128, bias=True)\n  )\n  (classifier): Linear(in_features=128, out_features=3, bias=True)\n  (activation): LogSoftmax(dim=-1)\n)'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[70], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpyannote\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39maudio\u001b[39;00m \u001b[39mimport\u001b[39;00m Pipeline\n\u001b[0;32m----> 2\u001b[0m pipeline \u001b[39m=\u001b[39m Pipeline\u001b[39m.\u001b[39;49mfrom_pretrained(model,\n\u001b[1;32m      3\u001b[0m                                     use_auth_token\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mACCESS_TOKEN_GOES_HERE\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/pyannote/audio/core/pipeline.py:88\u001b[0m, in \u001b[0;36mPipeline.from_pretrained\u001b[0;34m(cls, checkpoint_path, hparams_file, use_auth_token, cache_dir)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 revision \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     87\u001b[0m             \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 88\u001b[0m                 config_yml \u001b[39m=\u001b[39m hf_hub_download(\n\u001b[1;32m     89\u001b[0m                     model_id,\n\u001b[1;32m     90\u001b[0m                     PIPELINE_PARAMS_NAME,\n\u001b[1;32m     91\u001b[0m                     repo_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mmodel\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     92\u001b[0m                     revision\u001b[39m=\u001b[39;49mrevision,\n\u001b[1;32m     93\u001b[0m                     library_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpyannote\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     94\u001b[0m                     library_version\u001b[39m=\u001b[39;49m__version__,\n\u001b[1;32m     95\u001b[0m                     cache_dir\u001b[39m=\u001b[39;49mcache_dir,\n\u001b[1;32m     96\u001b[0m                     \u001b[39m# force_download=False,\u001b[39;49;00m\n\u001b[1;32m     97\u001b[0m                     \u001b[39m# proxies=None,\u001b[39;49;00m\n\u001b[1;32m     98\u001b[0m                     \u001b[39m# etag_timeout=10,\u001b[39;49;00m\n\u001b[1;32m     99\u001b[0m                     \u001b[39m# resume_download=False,\u001b[39;49;00m\n\u001b[1;32m    100\u001b[0m                     use_auth_token\u001b[39m=\u001b[39;49muse_auth_token,\n\u001b[1;32m    101\u001b[0m                     \u001b[39m# local_files_only=False,\u001b[39;49;00m\n\u001b[1;32m    102\u001b[0m                     \u001b[39m# legacy_cache_layout=False,\u001b[39;49;00m\n\u001b[1;32m    103\u001b[0m                 )\n\u001b[1;32m    105\u001b[0m             \u001b[39mexcept\u001b[39;00m RepositoryNotFoundError:\n\u001b[1;32m    106\u001b[0m                 \u001b[39mprint\u001b[39m(\n\u001b[1;32m    107\u001b[0m                     \u001b[39mf\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    108\u001b[0m \u001b[39mCould not download \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmodel_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m pipeline.\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[39mvisit https://hf.co/\u001b[39m\u001b[39m{\u001b[39;00mmodel_id\u001b[39m}\u001b[39;00m\u001b[39m to accept the user conditions.\u001b[39m\u001b[39m\"\"\"\u001b[39m\n\u001b[1;32m    118\u001b[0m                 )\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:110\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[39mfor\u001b[39;00m arg_name, arg_value \u001b[39min\u001b[39;00m chain(\n\u001b[1;32m    106\u001b[0m     \u001b[39mzip\u001b[39m(signature\u001b[39m.\u001b[39mparameters, args),  \u001b[39m# Args values\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     kwargs\u001b[39m.\u001b[39mitems(),  \u001b[39m# Kwargs values\u001b[39;00m\n\u001b[1;32m    108\u001b[0m ):\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m arg_name \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mrepo_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfrom_id\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mto_id\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[0;32m--> 110\u001b[0m         validate_repo_id(arg_value)\n\u001b[1;32m    112\u001b[0m     \u001b[39melif\u001b[39;00m arg_name \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mtoken\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m arg_value \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    113\u001b[0m         has_token \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/micromamba/envs/broadcastify/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:164\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    159\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must be in the form \u001b[39m\u001b[39m'\u001b[39m\u001b[39mrepo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m or \u001b[39m\u001b[39m'\u001b[39m\u001b[39mnamespace/repo_name\u001b[39m\u001b[39m'\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    160\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m. Use `repo_type` argument if needed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    163\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m REPO_ID_REGEX\u001b[39m.\u001b[39mmatch(repo_id):\n\u001b[0;32m--> 164\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    165\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mRepo id must use alphanumeric chars or \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m_\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m--\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m..\u001b[39m\u001b[39m'\u001b[39m\u001b[39m are\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    166\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m forbidden, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m-\u001b[39m\u001b[39m'\u001b[39m\u001b[39m and \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m\u001b[39m cannot start or end the name, max length is 96:\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    167\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    170\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m--\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m repo_id \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m..\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m repo_id:\n\u001b[1;32m    171\u001b[0m     \u001b[39mraise\u001b[39;00m HFValidationError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot have -- or .. in repo_id: \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mrepo_id\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mHFValidationError\u001b[0m: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: 'PyanNet(\n  (sincnet): SincNet(\n    (wav_norm1d): InstanceNorm1d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n    (conv1d): ModuleList(\n      (0): Encoder(\n        (filterbank): ParamSincFB()\n      )\n      (1): Conv1d(80, 60, kernel_size=(5,), stride=(1,))\n      (2): Conv1d(60, 60, kernel_size=(5,), stride=(1,))\n    )\n    (pool1d): ModuleList(\n      (0-2): 3 x MaxPool1d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n    )\n    (norm1d): ModuleList(\n      (0): InstanceNorm1d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n      (1-2): 2 x InstanceNorm1d(60, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n    )\n  )\n  (lstm): LSTM(60, 128, num_layers=4, batch_first=True, dropout=0.5, bidirectional=True)\n  (linear): ModuleList(\n    (0): Linear(in_features=256, out_features=128, bias=True)\n    (1): Linear(in_features=128, out_features=128, bias=True)\n  )\n  (classifier): Linear(in_features=128, out_features=3, bias=True)\n  (activation): LogSoftmax(dim=-1)\n)'."
     ]
    }
   ],
   "source": [
    "from pyannote.audio import Pipeline\n",
    "pipeline = Pipeline.from_pretrained(model,\n",
    "                                    use_auth_token=\"ACCESS_TOKEN_GOES_HERE\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattr__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_flatten',\n",
       " '_flattened_parameters',\n",
       " '_unflatten',\n",
       " 'classes',\n",
       " 'default_parameters',\n",
       " 'dump_params',\n",
       " 'freeze',\n",
       " 'from_pretrained',\n",
       " 'get_direction',\n",
       " 'get_metric',\n",
       " 'initialize',\n",
       " 'instantiate',\n",
       " 'instantiated',\n",
       " 'load_params',\n",
       " 'loss',\n",
       " 'parameters',\n",
       " 'setup_hook',\n",
       " 'to',\n",
       " 'training',\n",
       " 'write',\n",
       " 'write_format',\n",
       " 'write_rttm',\n",
       " 'write_txt']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(Pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
